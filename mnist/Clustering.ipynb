{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explain import L2X, generate_model_preds\n",
    "from keras.engine.topology import Layer \n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample_Concrete(Layer):\n",
    "    \"\"\"\n",
    "    Layer for sample Concrete / Gumbel-Softmax variables. \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, tau0, k, **kwargs): \n",
    "        self.tau0 = tau0\n",
    "        self.k = k\n",
    "        super(Sample_Concrete, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, logits):   \n",
    "        # logits: [batch_size, d, 1]\n",
    "        logits_ = K.expand_dims(logits, -2) #transform to Batch x 1 x Dim\n",
    "\n",
    "        d = int(logits_.get_shape()[2]) #d = 784 in this case\n",
    "        unif_shape = [batch_size,self.k,d] #sizing the sampling.\n",
    "\n",
    "        uniform = K.random_uniform_variable(shape=unif_shape,\n",
    "            low = np.finfo(tf.float32.as_numpy_dtype).tiny,\n",
    "            high = 1.0) #finfo is machine limit for floating precision - this is the draw from a Uniform for Gumbel sftmx\n",
    "        gumbel = - K.log(-K.log(uniform)) #This is now a tf.tensor; tf.variables are converted to Tensors once used\n",
    "        noisy_logits = (gumbel + logits_)/self.tau0 \n",
    "        samples = K.softmax(noisy_logits) #In this context, logits are just 'raw activations'\n",
    "        samples = K.max(samples, axis = 1) #reduces to max of the softmax (i.e. batch x 784)\n",
    "        \n",
    "        logits = tf.reshape(logits,[-1, d]) #Not sure necessary for our dimensions\n",
    "        threshold = tf.expand_dims(tf.nn.top_k(logits, self.k, sorted = True)[0][:,-1], -1) #gives a batchx1 tensor.\n",
    "                #this is taking the 10th highest logit value as a threshold for each instance\n",
    "        discrete_logits = tf.cast(tf.greater_equal(logits,threshold),tf.float32) #Does what you think. Returns a Batch x d vec of zeros or ones \n",
    "        \n",
    "        output = K.in_train_phase(samples, discrete_logits) #Returns samples if in training, discrete_logits otherwise.\n",
    "        return output #tf.expand_dims(output,-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_model(train = True):\n",
    "    \"\"\"\n",
    "    Build simple MNIST model in Keras, and train it if train = True\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    x_train, y_train, x_val, y_val = load_data()\n",
    "\n",
    "    if train:\n",
    "        filepath=\"models/original.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "            verbose=1, save_best_only=True, mode='max')\n",
    "        callbacks_list = [checkpoint]\n",
    "        model.fit(x_train, y_train, validation_data=(x_val, y_val),callbacks = callbacks_list, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    model.load_weights('./models/original.hdf5',by_name=True) #If train=False, we assume we have already trained an instance of the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load Data from keras mnist dataset, adjust to appropriate dimensions range etc.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_val = x_val.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_val /= 255\n",
    "    \n",
    "    yy_train = np.zeros(y_train.shape)\n",
    "    yy_val = np.zeros(y_val.shape)\n",
    "    \n",
    "    for idx, value in enumerate(y_train):\n",
    "        if value > 4:\n",
    "            yy_train[idx] = 1\n",
    "            \n",
    "    for idx, value in enumerate(y_val):\n",
    "        if value > 4:\n",
    "            yy_val[idx] = 1\n",
    "    \n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_val = keras.utils.to_categorical(y_val, 10)\n",
    "    \n",
    "    yy_train = keras.utils.to_categorical(yy_train, 2)\n",
    "    yy_val = keras.utils.to_categorical(yy_val, 2)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, yy_train, yy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, yy_train, yy_val = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
